# Movies-ETL

# Project Summary

Amazing Prime loves the dataset and wants to keep it updated on a daily basis. Fortunately, Wikipedia has a ton of information about movies, including budgets and box office returns, cast and crew, production and distribution, and so much more. Considering it a great resource, one of the Amazing Prime's employee Britta, needs a help to create an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables. So, the scope will be to refactor the codes and performs ETL process with requisite analysis. 

## Resources

## Software & Data Tool Used:
-  PostgreSQL ,pgAdmin , Jupyter Notebook with Python library, VS Code

## Data Source:
- Wikipedia-movies.json , movies_metadata.csv & ratings.csv from Kaggle

## Outcome & Analysis
- ETL function performed to read three data files
- Extract and transform entire wikipedia data
- Extract and transform the Kaggle data
- Load the data and transfer to a posgtreSQL
- Tranformed & Merge data, ready to further used for Analysis.
